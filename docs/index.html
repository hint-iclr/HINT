
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>
<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-121802070-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-121802070-1');
</script>
<meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
<style type="text/css">
a {
color: #000080;
text-decoration:none;
}

a:focus, a:hover {
color: #000080;
text-decoration:underline;
}

a.hover
{
    text-decoration: none;
}

a.hover:hover
 {
    text-decoration: underline;
 }

.bibtab { margin-left: 1em; 
	text-indent: -1em;
}


body,td,th {
	font-family: Lora;
	font-size: 16px;
	font-weight: 400;
}
papertitle {
	font-family: Lora;
	font-size: 18px;
	font-weight: 600;
}

hr { 
    display: block;
    margin-bottom: 0.5em;
    margin-top: -0.5em;
    margin-left: auto;
    margin-right: auto;
    border-width: 2px;
}

.un {
	font-family: Italian;
	font-size: 25px;
	text-align: center;
	font-weight:800;
}

strong {
	font-family: Lora;
	font-size: 18px;
	font-weight: 800
}
heading {
	font-family: Lora;
	color: #970024; /*#EB6400;*/
	font-size: 22px;
	font-weight: bold;
}
pvenue {
	display: inline-block;
	color: #500;
}
pkeywords{
	color: #EB6400;
}
</style>
    <!-- Custom Fonts -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
<link rel="icon" type="image/png" href="seal_icon.png">
<link href="css/styles.css" rel="stylesheet">
<title>HINT</title>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>

<div id="Banner">
    <div height="80" id="header" style="background-color:#FFFFFF; color: #FFFFFF">
      <center>
        <table width="1100" height="80" border="0">
      	<tr>
		<td halign="center">
			<p class=un>A Minimalist Dataset for Systematic Generalization of Perception, Syntax, and Semantics</p>
			<hr >
		</td>
		</tr>
        </table>
      </center>
    </div>
</div>

<div id="main" style="padding-bottom:1em; padding-top: 2em; width: 70em; max-width: 70em; margin-left: auto; margin-right: auto;">
<br>
<heading>Abstract</heading>
<p>
Inspired by humans' remarkable ability to master arithmetic and generalize to unseen problems, we present a new dataset, HINT, to study machines' capability of learning generalizable concepts at three different levels: perception, syntax, and semantics. Learning agents are tasked to reckon how concepts are perceived from raw signals such as images (i.e., perception), how multiple concepts are structurally combined to form a valid expression (i.e., syntax), and how concepts are realized to afford various reasoning tasks (i.e., semantics), all in a weakly supervised manner. With a focus on systematic generalization, we carefully design a five-fold test set to evaluate both the interpolation} and the extrapolation of learned concepts w.r.t. the three levels. We further design a few-shot learning split to test whether models could quickly learn new concepts and generalize them to more complex scenarios. To understand existing models' limitations, we conduct extensive experiments with various sequence-to-sequence models, including RNNs, Transformers, and GPT-3 (with the chain of thought prompting). The results suggest that current models still struggle in extrapolation to long-range syntactic dependency and semantics. Models show a significant gap toward human-level generalization when tested with new concepts in a few-shot setting. Moreover, we find that it is infeasible to solve HINT by simply scaling up the dataset and the model size; this strategy barely helps the extrapolation over syntax and semantics. Finally, in zero-shot GPT-3 experiments, the chain of thought prompting shows impressive results and significantly boosts the test accuracy. We believe the proposed dataset together with the experimental findings are of great interest to the community on systematic generalization.
</p>
</div>

<div id="main" style="padding-bottom:0em; padding-top: 0em; width: 70em; max-width: 70em; margin-left: auto; margin-right: auto;">
<heading>Paper</heading> <br>
<papertitle>A Minimalist Dataset for Systematic Generalization of Perception, Syntax, and Semantics</papertitle> <br />
 					Under review. <br />
					<a href="https://github.com/hint-iclr/HINT/raw/master/data/dataset.tar.xz">Dataset</a> /
					<a href="https://github.com/hint-iclr/HINT">Code</a> /
					<a href="https://wandb.ai/qli/HINT/reports/HINT-experimental-report--VmlldzoyNzAyOTIy">Experiments (Weights & Bias)</a>
</div>
<br>

<div id="main" style="padding-bottom:0em; padding-top: 0em; width: 70em; max-width: 70em; margin-left: auto; margin-right: auto;">
<heading>Experiments</heading> <br>
<iframe src="https://wandb.ai/qli/HINT/reports/HINT-experimental-report--VmlldzoyNzAyOTIy" style="border:none;height:1024px;width:100%"></iframe>
</div>



<div id="main" style="padding-bottom:1em; padding-top: 0em; width: 80em; max-width: 70em; margin-left: auto; margin-right: auto;">

